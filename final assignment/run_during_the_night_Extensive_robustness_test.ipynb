{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Alles runnen totdat je CODE MEREL ziet, dan het blokje runnen met jouw naam!",
   "id": "74bddebf2273867c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    "    Samplers,\n",
    ")\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "\n",
    "# Define the folder path and get list of files\n",
    "folder_name = \"selected_4_policies\"\n",
    "file_list = os.listdir(folder_name)\n",
    "\n",
    "# Initialize empty lists to hold dataframes for policies_20 and policies_21\n",
    "policies_20_dfs = []\n",
    "policies_21_dfs = []\n",
    "\n",
    "for file in file_list:\n",
    "    if file.endswith('.csv'):\n",
    "        # Read the CSV\n",
    "        df = pd.read_csv(os.path.join(folder_name, file), nrows=1)\n",
    "\n",
    "        # Check if file name contains \"_20_\" or \"_21_\" and add sliced df accordingly\n",
    "        if '_20_' in file:\n",
    "            # Take rows 20 to 50 by index (i.e. iloc[19:50])\n",
    "            policies_20_dfs.append(df)\n",
    "        elif '_21_' in file:\n",
    "            policies_21_dfs.append(df)\n",
    "\n",
    "\n",
    "policies_20_df = pd.concat(policies_20_dfs, ignore_index=True).iloc[:, 19:50]\n",
    "policies_21_df = pd.concat(policies_21_dfs, ignore_index=True).iloc[:, 19:50]"
   ],
   "id": "4384914bf647cd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policies_20 = []\n",
    "\n",
    "for idx, row in policies_20_df.iterrows():\n",
    "    # Convert the row (pandas Series) to a dictionary: lever_name -> lever_value\n",
    "    lever_values = row.to_dict()\n",
    "\n",
    "    # Create a unique policy name, e.g. \"policy_20_row_0\"\n",
    "    policy_name = f\"policy_20_row_{idx}\"\n",
    "\n",
    "    # Create the Policy object\n",
    "    policy = Policy(policy_name, **lever_values)\n",
    "\n",
    "    # Append to the list\n",
    "    policies_20.append(policy)\n",
    "\n",
    "policies_21 = []\n",
    "\n",
    "for idx, row in policies_21_df.iterrows():\n",
    "    # Convert the row (pandas Series) to a dictionary: lever_name -> lever_value\n",
    "    lever_values = row.to_dict()\n",
    "\n",
    "    # Create a unique policy name, e.g. \"policy_20_row_0\"\n",
    "    policy_name = f\"policy_21_row_{idx}\"\n",
    "\n",
    "    # Create the Policy object\n",
    "    policy = Policy(policy_name, **lever_values)\n",
    "\n",
    "    # Append to the list\n",
    "    policies_21.append(policy)\n",
    "\n"
   ],
   "id": "64784d5d721e3071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def save_experiments_and_outcomes(name, experiments, outcomes, folder_name=\"robustness_results\"):\n",
    "    \"\"\"\n",
    "    Saves the experiments and outcomes to CSV files in the specified folder,\n",
    "    with filenames that include a custom name and timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): Custom label for the output files (e.g., 'policy6_seed20').\n",
    "    - experiments (pd.DataFrame): The experiments DataFrame.\n",
    "    - outcomes (dict): The outcomes dictionary from the EMA Workbench.\n",
    "    - folder_name (str): The name of the folder where files will be saved. Default is \"results\".\n",
    "    \"\"\"\n",
    "    # Get timestamp\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Ensure folder exists\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Define file paths\n",
    "    exp_path = os.path.join(folder_name, f'{name}_robustness_100000_experiments_{current_date}.csv')\n",
    "    out_path = os.path.join(folder_name, f'{name}_robustness_100000_outcomes_{current_date}.csv')\n",
    "\n",
    "    # Save experiments\n",
    "    experiments.to_csv(exp_path, index=False)\n",
    "\n",
    "    # Flatten outcomes and save\n",
    "    flattened_data = {key: value.flatten() for key, value in outcomes.items()}\n",
    "    df_outcomes = pd.DataFrame(flattened_data)\n",
    "    df_outcomes.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"Saved experiments and outcomes as '{name}' in '{folder_name}' (timestamp: {current_date})\")\n"
   ],
   "id": "a50ff45e8d2af918"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CODE MEREL",
   "id": "a4e33785c677ef31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_scenarios = 100000\n",
    "np.random.seed(21)\n",
    "policy = policies_20[0]\n",
    "\n",
    "# Load your model and define parameters\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(\n",
    "        scenarios=n_scenarios,\n",
    "        policies=policy,\n",
    "        uncertainty_sampling=Samplers.LHS\n",
    "    )\n",
    "\n",
    "experiments, outcomes = results\n",
    "save_experiments_and_outcomes('policy_6_s20', experiments, outcomes)\n"
   ],
   "id": "607d5e508dc54c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CODE TWAN",
   "id": "52b674d617aeaa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_scenarios = 100000\n",
    "np.random.seed(21)\n",
    "policy = policies_20[1]\n",
    "\n",
    "# Load your model and define parameters\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(\n",
    "        scenarios=n_scenarios,\n",
    "        policies=policy,\n",
    "        uncertainty_sampling=Samplers.LHS\n",
    "    )\n",
    "\n",
    "experiments, outcomes = results\n",
    "save_experiments_and_outcomes('policy_8_s20', experiments, outcomes)\n"
   ],
   "id": "6e87f47cb46296ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CODE JESSE",
   "id": "1586cd138bd202fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_scenarios = 100000\n",
    "np.random.seed(21)\n",
    "policy = policies_21[0]\n",
    "\n",
    "# Load your model and define parameters\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(\n",
    "        scenarios=n_scenarios,\n",
    "        policies=policy,\n",
    "        uncertainty_sampling=Samplers.LHS\n",
    "    )\n",
    "\n",
    "experiments, outcomes = results\n",
    "save_experiments_and_outcomes('policy_7_s21', experiments, outcomes)\n"
   ],
   "id": "3e898800184914a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CODE PIEN",
   "id": "9d95d2d1fc5f43cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_scenarios = 100000\n",
    "np.random.seed(21)\n",
    "policy = policies_21[1]\n",
    "\n",
    "# Load your model and define parameters\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(\n",
    "        scenarios=n_scenarios,\n",
    "        policies=policy,\n",
    "        uncertainty_sampling=Samplers.LHS\n",
    "    )\n",
    "\n",
    "experiments, outcomes = results\n",
    "save_experiments_and_outcomes('policy_8_s21', experiments, outcomes)\n"
   ],
   "id": "68229a760f9c69e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder with the 4 policy CSVs\n",
    "folder_path = \"selected_4_policies\"\n",
    "\n",
    "# Desired policies and their filenames expected in the folder\n",
    "policy_files = {\n",
    "    \"Policy 6 (Seed 20)\": \"policy_6_overview_20.csv\",\n",
    "    \"Policy 8 (Seed 20)\": \"policy_8_overview_20.csv\",\n",
    "    \"Policy 7 (Seed 21)\": \"policy_7_overview_21.csv\",\n",
    "    \"Policy 8 (Seed 21)\": \"policy_8_overview_21.csv\"\n",
    "}\n",
    "\n",
    "# The parameter columns you want as rows\n",
    "parameter_columns = [\n",
    "    \"0_RfR 0\", \"0_RfR 1\", \"0_RfR 2\",\n",
    "    \"1_RfR 0\", \"1_RfR 1\", \"1_RfR 2\",\n",
    "    \"2_RfR 0\", \"2_RfR 1\", \"2_RfR 2\",\n",
    "    \"3_RfR 0\", \"3_RfR 1\", \"3_RfR 2\",\n",
    "    \"4_RfR 0\", \"4_RfR 1\", \"4_RfR 2\",\n",
    "    \"EWS_DaysToThreat\",\n",
    "    \"A.1_DikeIncrease 0\", \"A.1_DikeIncrease 1\", \"A.1_DikeIncrease 2\",\n",
    "    \"A.2_DikeIncrease 0\", \"A.2_DikeIncrease 1\", \"A.2_DikeIncrease 2\",\n",
    "    \"A.3_DikeIncrease 0\", \"A.3_DikeIncrease 1\", \"A.3_DikeIncrease 2\",\n",
    "    \"A.4_DikeIncrease 0\", \"A.4_DikeIncrease 1\", \"A.4_DikeIncrease 2\",\n",
    "    \"A.5_DikeIncrease 0\", \"A.5_DikeIncrease 1\", \"A.5_DikeIncrease 2\"\n",
    "]\n",
    "\n",
    "# Create an empty dict to hold each policy's data\n",
    "policy_data = {}\n",
    "\n",
    "for policy_name, filename in policy_files.items():\n",
    "    filepath = os.path.join(folder_path, filename)\n",
    "    if not os.path.isfile(filepath):\n",
    "        raise FileNotFoundError(f\"File {filepath} not found!\")\n",
    "\n",
    "    # Load CSV, first row only (policy parameters)\n",
    "    df = pd.read_csv(filepath, nrows=1)\n",
    "\n",
    "    # Remove unwanted 'combined_policy_parameters' column if it exists\n",
    "    if 'combined_policy_parameters' in df.columns:\n",
    "        df = df.drop(columns=['combined_policy_parameters'])\n",
    "\n",
    "    # Select only the parameter columns requested (ignore missing columns silently)\n",
    "    cols_to_select = [col for col in parameter_columns if col in df.columns]\n",
    "\n",
    "    # Extract that slice and flatten to Series (index=parameter names)\n",
    "    policy_params = df[cols_to_select].iloc[0]\n",
    "\n",
    "    # Save under policy name\n",
    "    policy_data[policy_name] = policy_params\n",
    "\n",
    "# Combine into one DataFrame: rows = parameters, columns = policies\n",
    "final_table = pd.DataFrame(policy_data)\n",
    "\n",
    "# Save to CSV with index=True to keep parameter names\n",
    "output_path = os.path.join(folder_path, \"combined_policies_parameters.csv\")\n",
    "final_table.to_csv(output_path, index=True)\n",
    "\n",
    "print(f\"Combined policy parameters saved to {output_path}\")\n",
    "final_table\n"
   ],
   "id": "efc8b8977d533802"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f0e17b6c8198123b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "502c8046d17e2e3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e35b7850c539406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4bd8227847bc8238"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

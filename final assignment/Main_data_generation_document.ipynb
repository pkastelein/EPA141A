{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9827ea2",
   "metadata": {},
   "source": [
    "In this notebook, the data used to produce the key figures in the results section can be generated. In the file Main_document.ipynb, the data is used to create the figures. First the necessary libraries are imported. Problem formulation id 2 is mostly used in the generation of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    Scenario,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    "    Samplers,\n",
    ")\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "\n",
    "# Display all columns in the DataFrame\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a209f",
   "metadata": {},
   "source": [
    "Firstly, we define a function allowing us to save the results of a run, with a name and a set folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiments_and_outcomes(name, experiments, outcomes, folder_name=\"sobol_results\"):\n",
    "    \"\"\"\n",
    "    Saves the experiments and outcomes to CSV files in the specified folder,\n",
    "    with filenames that include a custom name and timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): Custom label for the output files (e.g., 'policy6_seed20').\n",
    "    - experiments (pd.DataFrame): The experiments DataFrame.\n",
    "    - outcomes (dict): The outcomes dictionary from the EMA Workbench.\n",
    "    - folder_name (str): The name of the folder where files will be saved. Default is \"results\".\n",
    "    \"\"\"\n",
    "    # Get timestamp\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Ensure folder exists\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Define file paths\n",
    "    exp_path = os.path.join(folder_name, f'{name}_experiments_{current_date}.csv')\n",
    "    out_path = os.path.join(folder_name, f'{name}_policies_{current_date}.csv')\n",
    "\n",
    "    # Save experiments\n",
    "    experiments.to_csv(exp_path, index=False)\n",
    "\n",
    "    # Flatten outcomes and save\n",
    "    flattened_data = {key: value.flatten() for key, value in outcomes.items()}\n",
    "    df_outcomes = pd.DataFrame(flattened_data)\n",
    "    df_outcomes.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"Saved experiments and outcomes as '{name}' in '{folder_name}' (timestamp: {current_date})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8f826",
   "metadata": {},
   "source": [
    "## Open Exploration\n",
    "\n",
    "### 'Zero policy'\n",
    "In this section of the notebook, the data required for the subsection 'Zero Policy' are generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076a778",
   "metadata": {},
   "source": [
    "## Hier doe jij dingen PIEN!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d756e",
   "metadata": {},
   "source": [
    "### Subspace partitioning\n",
    "In this section of the notebook, the data required for the subsection Subspace partitioning are generated. The Latin hypercube sample consists of 400 scenarios and 600 policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65318f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 600\n",
    "n_policies = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to get the LHS data for the subspace partitioning\n",
    "np.random.seed(21)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=n_policies, uncertainty_sampling=Samplers.LHS, lever_sampling=Samplers.LHS)\n",
    "experiments, outcomes = results\n",
    "save_experiments_and_outcomes('LHS_using_pf2', experiments, outcomes, folder_name=\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a1574",
   "metadata": {},
   "source": [
    "## Sensitivity analysis (Sobol Indices)\n",
    "In this section of the notebook, the data required for the subsection Sobol Indices are generated. The zero-policy and an average scenario are defined and then used to perform experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ff2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with all levers set to 0\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "# Create a policy using the do-nothing dictionary\n",
    "policies = [\n",
    "    Policy(\n",
    "        \"policy 0\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict()\n",
    "        )\n",
    "    ),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe is used to show the average values of the uncertainty parameters\n",
    "df = pd.read_csv(\"results/scenario_space_100000_experiments_2025-06-11_21-41.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scenario with average values for the uncertainties\n",
    "reference_values = {\n",
    "    \"Bmax\": 190,\n",
    "    \"Brate\": 4.167,\n",
    "    \"pfail\": 0.5,\n",
    "    \"discount rate 0\": 3,\n",
    "    \"discount rate 1\": 3,\n",
    "    \"discount rate 2\": 3,\n",
    "    \"ID flood wave shape\": 4, # Arbritary value, there is no average value for this parameter\n",
    "}\n",
    "\n",
    "# Create a scenario dictionary and then a Scenario object\n",
    "scenario_dict = {}\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split(\"_\")\n",
    "    if len(name_split) == 1:\n",
    "        scenario_dict[key.name] = reference_values.get(key.name)\n",
    "    else:\n",
    "        scenario_dict[key.name] = reference_values.get(name_split[1])\n",
    "scenario = Scenario(\"default\", **scenario_dict)\n",
    "scenarios = [scenario,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b75096",
   "metadata": {},
   "source": [
    "Below the experiments can be run, the number of scenarios and policies chosen is very high, as this is needed to perform a sensitivity analysis using Sobol Indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The amount of scenarios and policies must be a power of two for the Sobol' sequence\n",
    "n_scenarios = 4096\n",
    "n_policies = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to get the sobol indices for the scenario space\n",
    "np.random.seed(21)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=policies, uncertainty_sampling=Samplers.SOBOL)\n",
    "experiments, outcomes = results\n",
    "# Save the experiments and outcomes to CSV files\n",
    "save_experiments_and_outcomes('SOBOL_scenarios', experiments, outcomes, folder_name=\"sobol_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70543f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to get the sobol indices for the policy space\n",
    "np.random.seed(21)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=scenarios, policies=n_policies, lever_sampling=Samplers.SOBOL)   \n",
    "experiments, outcomes = results\n",
    "# Save the experiments and outcomes to CSV files\n",
    "save_experiments_and_outcomes('SOBOL_policies', experiments, outcomes, folder_name=\"sobol_results\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Folder with outcome files\n",
    "folder_path = 'robustness_results'\n",
    "\n",
    "# Loop through files\n",
    "for filename in os.listdir(folder_path):\n",
    "    if '_outcomes_' in filename and filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        if all(col in df.columns for col in ['Expected Annual Damage', 'Expected Number of Deaths', 'Evacuation Costs']):\n",
    "            # Plot setup\n",
    "            fig = plt.figure(figsize=(10, 8))\n",
    "            gs = gridspec.GridSpec(2, 2, width_ratios=[4, 1], height_ratios=[1, 4], hspace=0.05, wspace=0.05)\n",
    "\n",
    "            # Scatter plot\n",
    "            ax_scatter = fig.add_subplot(gs[1, 0])\n",
    "            ax_scatter.scatter(\n",
    "                df['Expected Annual Damage'],\n",
    "                df['Expected Number of Deaths'],\n",
    "                color='blue',\n",
    "                alpha=0.05,  # Low opacity for dense plots\n",
    "                s=10\n",
    "            )\n",
    "            ax_scatter.set_xlabel('Expected Annual Damage')\n",
    "            ax_scatter.set_ylabel('Expected Number of Deaths')\n",
    "            ax_scatter.grid(True)\n",
    "\n",
    "            # Top histogram\n",
    "            ax_hist_x = fig.add_subplot(gs[0, 0], sharex=ax_scatter)\n",
    "            ax_hist_x.hist(df['Expected Annual Damage'], bins=30, color='gray', alpha=0.7)\n",
    "            ax_hist_x.axis('off')\n",
    "\n",
    "            # Right histogram\n",
    "            ax_hist_y = fig.add_subplot(gs[1, 1], sharey=ax_scatter)\n",
    "            ax_hist_y.hist(df['Expected Number of Deaths'], bins=30, orientation='horizontal', color='gray', alpha=0.7)\n",
    "            ax_hist_y.axis('off')\n",
    "\n",
    "            # Title\n",
    "            fig.suptitle(f'{filename}', fontsize=10)\n",
    "\n",
    "            # Layout and show\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping {filename}: missing required columns.\")\n"
   ],
   "id": "44915902adce270e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_path = 'robustness_results'\n",
    "\n",
    "\n",
    "# Generate a sequential colormap from warm (orange/red) to cool (blue)\n",
    "policy_colors = ['#b40426ff', '#f7b89cff', '#90ee90ff', '#3b4cc0ff']\n",
    "\n",
    "color_map = {}\n",
    "\n",
    "# Alpha levels from bottom to top\n",
    "alpha_levels = [0.8, 0.6, 0.4, 0.1]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2, width_ratios=[4, 1], height_ratios=[1, 4], hspace=0.05, wspace=0.05)\n",
    "ax_scatter = fig.add_subplot(gs[1, 0])\n",
    "ax_hist_x = fig.add_subplot(gs[0, 0], sharex=ax_scatter)\n",
    "ax_hist_y = fig.add_subplot(gs[1, 1], sharey=ax_scatter)\n",
    "\n",
    "all_damages = []\n",
    "all_deaths = []\n",
    "used_labels = set()\n",
    "\n",
    "for i, filename in enumerate(sorted(os.listdir(folder_path))):\n",
    "    if '_robustness_' in filename and filename.endswith('.csv'):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        if all(col in df.columns for col in ['Expected Annual Damage', 'Expected Number of Deaths']):\n",
    "            match = re.search(r'policy_(\\d+)_s(\\d+)', filename)\n",
    "            if match:\n",
    "                policy_id = match.group(1)\n",
    "                seed_id = match.group(2)\n",
    "                label = f\"Policy {policy_id} (seed {seed_id})\"\n",
    "\n",
    "                if label not in color_map:\n",
    "                    color_map[label] = policy_colors[len(color_map) % len(policy_colors)]\n",
    "                color = color_map[label]\n",
    "\n",
    "                alpha = alpha_levels[len(color_map)-1]  # assign alpha by order\n",
    "\n",
    "                ax_scatter.scatter(\n",
    "                    df['Expected Annual Damage'],\n",
    "                    df['Expected Number of Deaths'],\n",
    "                    color=color,\n",
    "                    label=label if label not in used_labels else None,\n",
    "                    alpha=alpha,\n",
    "                    s=12,\n",
    "                    edgecolors='none'\n",
    "                )\n",
    "                used_labels.add(label)\n",
    "\n",
    "                all_damages.extend(df['Expected Annual Damage'])\n",
    "                all_deaths.extend(df['Expected Number of Deaths'])\n",
    "\n",
    "# Histograms\n",
    "ax_hist_x.hist(all_damages, bins=30, color='gray', alpha=0.5)\n",
    "ax_hist_y.hist(all_deaths, bins=30, orientation='horizontal', color='gray', alpha=0.5)\n",
    "ax_hist_x.axis('off')\n",
    "ax_hist_y.axis('off')\n",
    "\n",
    "# Labels and legend\n",
    "ax_scatter.set_xlabel('Expected Annual Damage')\n",
    "ax_scatter.set_ylabel('Expected Number of Deaths')\n",
    "ax_scatter.grid(True)\n",
    "plt.suptitle('Joint Distribution of Damage and Deaths (Top 4 Policies, 100.000 Scenarios)', fontsize=14)\n",
    "\n",
    "ax_scatter.legend(title='Policy', markerscale=4, fontsize='small')\n",
    "\n",
    "output_folder = 'plots'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "save_path = os.path.join(output_folder, 'top_policies_plot.png')\n",
    "plt.savefig(save_path, facecolor='white', edgecolor='white', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "61decd72b3642009"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_robustness_with_regret(df, policy_id_col, scenario_id_col, performance_cols, weights):\n",
    "    regret_df = df.copy()\n",
    "\n",
    "    for col in performance_cols:\n",
    "        regret_df[f'{col} Regret'] = regret_df.groupby(scenario_id_col)[col].transform(lambda x: x - x.min())\n",
    "\n",
    "    grouped = regret_df.groupby(policy_id_col)\n",
    "    results = []\n",
    "\n",
    "    for policy, group in grouped:\n",
    "        metrics = {'Policy': policy}\n",
    "        for col in performance_cols:\n",
    "            values = group[col]\n",
    "            regrets = group[f'{col} Regret']\n",
    "            metrics[f'{col} Mean'] = values.mean()\n",
    "            metrics[f'{col} Std'] = values.std()\n",
    "            metrics[f'{col} Max Regret'] = regrets.max()\n",
    "            metrics[f'{col} Mean Regret'] = regrets.mean()\n",
    "        results.append(metrics)\n",
    "\n",
    "    robustness_df = pd.DataFrame(results)\n",
    "\n",
    "    for col in performance_cols:\n",
    "        for stat in ['Mean', 'Std', 'Max Regret', 'Mean Regret']:\n",
    "            metric_col = f'{col} {stat}'\n",
    "            min_val = robustness_df[metric_col].min()\n",
    "            max_val = robustness_df[metric_col].max()\n",
    "            denom = max_val - min_val if max_val > min_val else 1e-9\n",
    "            robustness_df[f'{metric_col} (Norm)'] = (robustness_df[metric_col] - min_val) / denom\n",
    "\n",
    "    score_cols = []\n",
    "    for col in performance_cols:\n",
    "        for stat, weight in zip(['Mean', 'Std', 'Max Regret', 'Mean Regret'], weights[col]):\n",
    "            norm_col = f'{col} {stat} (Norm)'\n",
    "            weighted_col = f'{col} {stat} Weighted'\n",
    "            robustness_df[weighted_col] = robustness_df[norm_col] * weight\n",
    "            score_cols.append(weighted_col)\n",
    "\n",
    "    robustness_df['Total Score'] = robustness_df[score_cols].sum(axis=1)\n",
    "\n",
    "    return robustness_df\n",
    "\n",
    "def analyze_outcomes_folder(folder_path, save_dir='analysis_outputs'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    all_dfs = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if '_outcomes_' in filename and filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            policy_id = filename.split('_')[1] + '_' + filename.split('_')[2]\n",
    "            df['policy'] = policy_id\n",
    "            df['scenario'] = df.index\n",
    "\n",
    "            if 'Dike Investment Costs' in df.columns and 'RfR Investment Costs' in df.columns:\n",
    "                df['Total Investment Costs'] = df['Dike Investment Costs'] + df['RfR Investment Costs']\n",
    "\n",
    "            if 'Evacuation Costs' in df.columns and 'Expected Annual Damage' in df.columns:\n",
    "                df['Expected Annual Costs'] = df['Evacuation Costs'] + df['Expected Annual Damage']\n",
    "\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    if not all_dfs:\n",
    "        raise ValueError(\"No outcome CSV files found with '_outcomes_' in filename.\")\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    performance_columns = [\n",
    "        'Expected Number of Deaths',\n",
    "        'Expected Annual Damage',\n",
    "        'Evacuation Costs',\n",
    "        'Total Investment Costs'\n",
    "    ]\n",
    "\n",
    "    weights = {\n",
    "        'Expected Number of Deaths': [1.0, 0.0, 1.0, 0.0],\n",
    "        'Expected Annual Damage':   [0.75, 0.75, 0.0, 0.5],\n",
    "        'Evacuation Costs':         [0.5, 0.5, 0.0, 0.25],\n",
    "        'Total Investment Costs':   [0.25, 0.25, 0.0, 0.0],\n",
    "    }\n",
    "\n",
    "    robustness_df = evaluate_robustness_with_regret(\n",
    "        combined_df,\n",
    "        policy_id_col='policy',\n",
    "        scenario_id_col='scenario',\n",
    "        performance_cols=performance_columns,\n",
    "        weights=weights\n",
    "    )\n",
    "\n",
    "    sorted_df = robustness_df.sort_values('Total Score').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    return sorted_df, combined_df\n",
    "\n",
    "def print_robustness_summary(sorted_df, performance_columns):\n",
    "    for i, row in sorted_df.iterrows():\n",
    "        print(f\"\\nRank {i+1} Policy: {row['Policy']}\")\n",
    "        print(f\"{'Metric':30} {'Mean':>15} {'Std':>15} {'Max Regret':>15} {'Mean Regret':>15}\")\n",
    "        print(\"-\" * 90)\n",
    "        for col in performance_columns:\n",
    "            print(f\"{col:30} \"\n",
    "                  f\"{row[f'{col} Mean']:15.6g} \"\n",
    "                  f\"{row[f'{col} Std']:15.6g} \"\n",
    "                  f\"{row[f'{col} Max Regret']:15.6g} \"\n",
    "                  f\"{row[f'{col} Mean Regret']:15.6g}\")\n",
    "\n",
    "# Usage\n",
    "folder_path = 'robustness_results'\n",
    "sorted_robustness_df, combined_outcomes_df = analyze_outcomes_folder(folder_path)\n",
    "\n",
    "performance_cols = [\n",
    "    'Expected Number of Deaths',\n",
    "    'Expected Annual Damage',\n",
    "    'Evacuation Costs',\n",
    "    'Total Investment Costs'\n",
    "]\n",
    "\n",
    "print_robustness_summary(sorted_robustness_df, performance_cols)\n"
   ],
   "id": "c67df19c3f02dc19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "combined_outcomes_df.to_csv(os.path.join(folder_path, 'combined_outcomes.csv'), index=False)\n",
    "sorted_robustness_df.to_csv(os.path.join(folder_path, 'robustness_summary.csv'), index=False)"
   ],
   "id": "36401978885aba4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2dbbdd7b298d027b"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}

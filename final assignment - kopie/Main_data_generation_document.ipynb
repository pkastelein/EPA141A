{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9827ea2",
   "metadata": {},
   "source": [
    "# Main notebook for generating the data\n",
    "\n",
    "In this notebook, the data used to produce the key figures in the results section can be generated. In the file Main_document.ipynb, the data is used to create the figures. First the necessary libraries are imported. Problem formulation id 2 is mostly used in the generation of data.\n",
    "\n",
    "We decided on using 2 main seeds:\n",
    "seed 20\n",
    "seed 21\n",
    "\n",
    "Unfortunately, somewhere in the code a seed of 42 was hardcoded. This is the only time another seed than the above two has been used. If a section of code has been executed with both seeds, this is mentioned in the description of hte code or the code itself.\n",
    "\n",
    "Parts of the code and comments were generated with help from large language models like ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "id": "0dadfefc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T22:59:18.450079Z",
     "start_time": "2025-06-19T22:59:14.457721Z"
    }
   },
   "source": [
    "import os\n",
    "import warnings\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "\n",
    "from ema_workbench import MultiprocessingEvaluator, Policy, Scenario, Samplers\n",
    "from ema_workbench.analysis import dimensional_stacking, parcoords, prim\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress, EpsNSGAII\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from ema_workbench.util import ema_logging\n",
    "\n",
    "\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Display all columns in pandas DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiments_and_outcomes(name, experiments, outcomes, folder_name=\"sobol_results\"):\n",
    "    \"\"\"\n",
    "    Saves the experiments and outcomes to CSV files in the specified folder,\n",
    "    with filenames that include a custom name and timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): Custom label for the output files (e.g., 'policy6_seed20').\n",
    "    - experiments (pd.DataFrame): The experiments DataFrame.\n",
    "    - outcomes (dict): The outcomes dictionary from the EMA Workbench.\n",
    "    - folder_name (str): The name of the folder where files will be saved. Default is \"results\".\n",
    "    \"\"\"\n",
    "    # Get timestamp\n",
    "\n",
    "    # Ensure folder exists\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Define file paths\n",
    "    exp_path = os.path.join(folder_name, f'{name}_experiments.csv')\n",
    "    out_path = os.path.join(folder_name, f'{name}_policies.csv')\n",
    "\n",
    "    # Save experiments\n",
    "    experiments.to_csv(exp_path, index=False)\n",
    "\n",
    "    # Flatten outcomes and save\n",
    "    flattened_data = {key: value.flatten() for key, value in outcomes.items()}\n",
    "    df_outcomes = pd.DataFrame(flattened_data)\n",
    "    df_outcomes.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"Saved experiments and outcomes as '{name}' in '{folder_name}')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8f826",
   "metadata": {},
   "source": [
    "## Open Exploration\n",
    "\n",
    "### 'Zero policy'\n",
    "In this section of the notebook, the data required for the subsection 'Zero Policy' are generated."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_scenarios = 100000\n",
    "\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "policies = [\n",
    "    Policy(\n",
    "        \"policy 0\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict()\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "np.random.seed(20)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=policies, uncertainty_sampling=Samplers.LHS)\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "folder_name = \"zero_policy_results\"\n",
    "experiments.to_csv(os.path.join(folder_name, f'scenario_space_100000_experiments.csv'), index=False)\n",
    "\n",
    "# Save outcomes DataFrame to a CSV file in the folder\n",
    "flattened_data = {key: value.flatten() for key, value in outcomes.items()}\n",
    "df_outcomes = pd.DataFrame(flattened_data)\n",
    "\n",
    "#df_outcomes = pd.DataFrame(outcomes)\n",
    "df_outcomes.to_csv(os.path.join(folder_name, f'scenario_space_100000_outcomes.csv'), index=False)\n",
    "\n",
    "print(f\"Experiments and outcomes saved in the '{folder_name}' folder.\")"
   ],
   "id": "ef3c7d9f28cc348c"
  },
  {
   "cell_type": "markdown",
   "id": "427d756e",
   "metadata": {},
   "source": [
    "### Subspace partitioning\n",
    "In this section of the notebook, the data required for the subsection Subspace partitioning are generated. The Latin hypercube sample consists of 400 scenarios and 600 policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65318f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 600\n",
    "n_policies = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to get the LHS data for the subspace partitioning\n",
    "np.random.seed(21)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=n_policies, uncertainty_sampling=Samplers.LHS, lever_sampling=Samplers.LHS)\n",
    "experiments, outcomes = results\n",
    "save_experiments_and_outcomes('LHS_using_pf2', experiments, outcomes, folder_name=\"LHS_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a1574",
   "metadata": {},
   "source": [
    "## Sensitivity analysis (Sobol Indices)\n",
    "In this section of the notebook, the data required for the subsection Sobol Indices are generated. The zero-policy and an average scenario are defined and then used to perform experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ff2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with all levers set to 0\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "# Create a policy using the do-nothing dictionary\n",
    "policies = [\n",
    "    Policy(\n",
    "        \"policy 0\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict()\n",
    "        )\n",
    "    ),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe is used to show the average values of the uncertainty parameters\n",
    "df = pd.read_csv(\"zero_policy_results/scenario_space_100000_experiments.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scenario with average values for the uncertainties\n",
    "reference_values = {\n",
    "    \"Bmax\": 190,\n",
    "    \"Brate\": 4.167,\n",
    "    \"pfail\": 0.5,\n",
    "    \"discount rate 0\": 3,\n",
    "    \"discount rate 1\": 3,\n",
    "    \"discount rate 2\": 3,\n",
    "    \"ID flood wave shape\": 4, # Arbritary value, there is no average value for this parameter\n",
    "}\n",
    "\n",
    "# Create a scenario dictionary and then a Scenario object\n",
    "scenario_dict = {}\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split(\"_\")\n",
    "    if len(name_split) == 1:\n",
    "        scenario_dict[key.name] = reference_values.get(key.name)\n",
    "    else:\n",
    "        scenario_dict[key.name] = reference_values.get(name_split[1])\n",
    "scenario = Scenario(\"default\", **scenario_dict)\n",
    "scenarios = [scenario,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b75096",
   "metadata": {},
   "source": [
    "Below the experiments can be run, the number of scenarios and policies chosen is very high, as this is needed to perform a sensitivity analysis using Sobol Indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The amount of scenarios and policies must be a power of two for the Sobol' sequence\n",
    "n_scenarios = 4096\n",
    "n_policies = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to get the sobol indices for the scenario space\n",
    "np.random.seed(21)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=policies, uncertainty_sampling=Samplers.SOBOL)\n",
    "experiments, outcomes = results\n",
    "# Save the experiments and outcomes to CSV files\n",
    "save_experiments_and_outcomes('SOBOL_scenarios', experiments, outcomes, folder_name=\"sobol_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70543f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to get the sobol indices for the policy space\n",
    "np.random.seed(21)\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=scenarios, policies=n_policies, lever_sampling=Samplers.SOBOL)   \n",
    "experiments, outcomes = results\n",
    "# Save the experiments and outcomes to CSV files\n",
    "save_experiments_and_outcomes('SOBOL_policies', experiments, outcomes, folder_name=\"sobol_results\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Optimization\n",
    "\n",
    "## Selecting the scenarios to optimize on\n",
    "Loading the data"
   ],
   "id": "cf2e8324af8a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:00:07.989542Z",
     "start_time": "2025-06-19T23:00:07.163799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the experiments DataFrame\n",
    "experiments = pd.read_csv(f\"zero_policy_results/scenario_space_100000_experiments.csv\")\n",
    "# Load the outcomes DataFrame\n",
    "outcomes = pd.read_csv(f\"zero_policy_results/scenario_space_100000_outcomes.csv\")\n",
    "combined_df = pd.concat([experiments, outcomes], axis=1)\n"
   ],
   "id": "71229a6b5292c5ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###\n",
    "Using defined bounds, sample scenarios from those bounds. We wanted to to this with seed 20 and seed 21, unfortunately we discovered later that a seed of 42 was hardcoded, which caused the sampled scenarios to be the same."
   ],
   "id": "c6a83861c9f79d1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:00:09.838150Z",
     "start_time": "2025-06-19T23:00:09.745121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define category-specific bounds\n",
    "favourable_bounds = [\n",
    "    [[0, 1], [0, 1]]  # 2 scenarios\n",
    "]\n",
    "\n",
    "unfavourable_bounds = [\n",
    "    [[6, float('inf')], [5, float('inf')]]  # 4 scenarios\n",
    "]\n",
    "\n",
    "medium_bounds = [\n",
    "    [[2.5, 3.5], [1.8, 2.8]],  # 2 scenarios\n",
    "    [[1.5, 2.5], [3, 4]]       # 2 scenarios\n",
    "]\n",
    "\n",
    "# Function to filter and sample based on bounds and desired number of samples\n",
    "def filter_and_sample(bounds_list, combined_df, n_per_bound):\n",
    "    results = pd.DataFrame()\n",
    "    for bound in bounds_list:\n",
    "        mask = (\n",
    "            (combined_df['Expected Annual Damage'] >= bound[0][0] * 1e9) &\n",
    "            (combined_df['Expected Annual Damage'] <= bound[0][1] * 1e9 if not np.isinf(bound[0][1]) else True) &\n",
    "            (combined_df['Expected Number of Deaths'] >= bound[1][0]) &\n",
    "            (combined_df['Expected Number of Deaths'] <= bound[1][1] if not np.isinf(bound[1][1]) else True)\n",
    "        )\n",
    "        filtered = combined_df[mask].copy()\n",
    "        if not filtered.empty:\n",
    "            sampled = filtered.sample(n=min(n_per_bound, len(filtered)), random_state=42) # Seed was predefined here :(\n",
    "            results = pd.concat([results, sampled], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"No outcomes found for bounds {bound}.\")\n",
    "    return results\n",
    "\n",
    "# Apply to each category\n",
    "favourable_scenarios_df = filter_and_sample(favourable_bounds, combined_df, 2).iloc[:, :-39]\n",
    "medium_scenarios_df = filter_and_sample(medium_bounds, combined_df, 2).iloc[:, :-39]\n",
    "unfavourable_scenarios_df = filter_and_sample(unfavourable_bounds, combined_df, 4).iloc[:, :-39]\n",
    "\n",
    "# Save to CSV\n",
    "favourable_scenarios_df.to_csv(\"scenarios/favourable_scenarios_df.csv\", index=False)\n",
    "unfavourable_scenarios_df.to_csv(\"scenarios/unfavourable_scenarios_df.csv\", index=False)\n",
    "medium_scenarios_df.to_csv(\"scenarios/medium_scenarios_df.csv\", index=False)\n",
    "\n",
    "combined_df = pd.concat([favourable_scenarios_df, medium_scenarios_df, unfavourable_scenarios_df], ignore_index=True)\n",
    "combined_df.to_csv(\"scenarios/filtered_scenario_space_df.csv\", index=False)\n"
   ],
   "id": "c40f182e2e3a4dfd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the following code, the MOEO code is defined.",
   "id": "137e19ea656f1c21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_optimization(nfe, epsilon, seed, scenario=None):\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    model, steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "    #Use default scenario if none is provided\n",
    "    if scenario is None:\n",
    "        reference_values = {\n",
    "            \"Bmax\": 175,\n",
    "            \"Brate\": 1.5,\n",
    "            \"pfail\": 0.5,\n",
    "            \"discount rate 0\": 3.5,\n",
    "            \"discount rate 1\": 3.5,\n",
    "            \"discount rate 2\": 3.5,\n",
    "            \"ID flood wave shape\": 4,\n",
    "        }\n",
    "        scenario_dict = {}\n",
    "        for key in model.uncertainties:\n",
    "            name_split = key.name.split(\"_\")\n",
    "            if len(name_split) == 1:\n",
    "                scenario_dict[key.name] = reference_values.get(key.name)\n",
    "            else:\n",
    "                scenario_dict[key.name] = reference_values.get(name_split[1])\n",
    "        scenario = Scenario(\"default\", **scenario_dict)\n",
    "\n",
    "    epsilons = [epsilon] * len(model.outcomes)\n",
    "    convergence_metrics = [EpsilonProgress()]\n",
    "\n",
    "\n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        results, convergence = evaluator.optimize(\n",
    "            nfe=nfe,\n",
    "            searchover=\"levers\",\n",
    "            algorithm=EpsNSGAII,\n",
    "            algorithm_kwargs={\n",
    "                \"epsilons\": epsilons,\n",
    "                \"problem\": scenario,\n",
    "                \"seed\": seed, # Seed run 1 = 20, seed run 2 = 21\n",
    "            },\n",
    "            convergence=convergence_metrics,\n",
    "            reference=scenario,\n",
    "            epsilons=epsilons,\n",
    "    )\n",
    "\n",
    "    return results, convergence\n",
    "\n",
    "def save_results_to_csv(result, name, seed):\n",
    "\n",
    "    # Define the folder path\n",
    "    folder_name = f\"optimization_150000_seed{seed}_results\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)  # Create the folder if it doesn't exist\n",
    "\n",
    "    # Save outcomes DataFrame to a CSV file in the folder\n",
    "    df_result = pd.DataFrame(result)\n",
    "    df_result.to_csv(os.path.join(folder_name, f'{name}_{current_date}.csv'), index=False)\n",
    "\n",
    "    print(f\"Saved {name}\")"
   ],
   "id": "fcf18d294824a663"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the run_scenarios function, the dataframes and epsilon and nfe values are given to then run for each df the optimization and save the results.Initally, we used a for loop to also run these optimizations for a smaller nfe to test different epsilon and later also different nfe",
   "id": "86cfb077bd43db40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_scenarios(unfavourable_scenarios_df, medium_scenarios_df, favourable_scenarios_df, seed, epsilon_value, nfe_value):\n",
    "    num = 0\n",
    "\n",
    "    for items in unfavourable_scenarios_df.iterrows():\n",
    "        print(f\"Running unfavourable scenario {num}...\")\n",
    "        scenario_dict = unfavourable_scenarios_df.iloc[num].to_dict()\n",
    "        scenario = Scenario(f\"unfavourable{num}\", **scenario_dict)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        result, convergence = run_optimization(epsilon=epsilon_value, nfe=nfe_value, seed=seed,scenario=scenario)\n",
    "\n",
    "        save_results_to_csv(result, f\"unfavourable_outcomes_{nfe_value}_run{seed}_{num}\", seed)\n",
    "        save_results_to_csv(convergence, f\"unfavourable_convergence_{nfe_value}_run{seed}_{num}\", seed)\n",
    "        num += 1\n",
    "\n",
    "    num = 0\n",
    "    for items in medium_scenarios_df.iterrows():\n",
    "        print(f\"Running medium scenario {num}...\")\n",
    "        scenario_dict = medium_scenarios_df.iloc[num].to_dict()\n",
    "        scenario = Scenario(f\"medium{num}\", **scenario_dict)\n",
    "        result, convergence = run_optimization(epsilon=epsilon_value, nfe=nfe_value, seed=seed, scenario=scenario)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        save_results_to_csv(result, f\"medium_outcomes_{nfe_value}_run{seed}_{num}\", seed)\n",
    "        save_results_to_csv(convergence, f\"medium_convergence_{nfe_value}_run{seed}_{num}\", seed)\n",
    "        num += 1\n",
    "\n",
    "    num = 0\n",
    "    for items in favourable_scenarios_df.iterrows():\n",
    "        print(f\"Running favourable scenario {num}...\")\n",
    "        scenario_dict = favourable_scenarios_df.iloc[num].to_dict()\n",
    "        scenario = Scenario(f\"favourable{num}\", **scenario_dict)\n",
    "        result, convergence = run_optimization(epsilon=epsilon_value, nfe=nfe_value, scenario=scenario)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        save_results_to_csv(result, f\"favourable_outcomes_150000_run{seed}_{num}\", seed)\n",
    "        save_results_to_csv(convergence, f\"favourable_convergence_150000_run{seed}_{num}\", seed)\n",
    "        num += 1\n",
    "\n",
    "run_scenarios(unfavourable_scenarios_df, medium_scenarios_df, favourable_scenarios_df, 20, 1000, 150000)\n",
    "run_scenarios(unfavourable_scenarios_df, medium_scenarios_df, favourable_scenarios_df, 21, 1000, 150000)"
   ],
   "id": "2e0d5ae28f4e92be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# After creating pareto fronts, select correct policies\n",
    "The previous code made pareto fronts, now this data is loaded in"
   ],
   "id": "c7d80272a92bd12f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:04:45.535711Z",
     "start_time": "2025-06-19T23:04:45.451565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_scenario_folder(folder):\n",
    "    \"\"\"\n",
    "    Loads and combines CSV files from a folder by scenario type ('favourable', 'medium', 'unfavourable').\n",
    "    Adds 'Total Investment Costs' and 'Expected Annual Costs' columns, and labels each row with a scenario ID.\n",
    "\n",
    "    Parameters:\n",
    "    - folder (str): Path to the folder containing scenario CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - favourable_df, unfavourable_df, medium_df (DataFrames): Combined data for each scenario type.\n",
    "    \"\"\"\n",
    "    # === Step 1: List and categorize CSV files ===\n",
    "    files = os.listdir(folder)\n",
    "    favourable_files = [f for f in files if f.startswith(\"favourable_outcomes\")]\n",
    "    unfavourable_files = [f for f in files if f.startswith(\"unfavourable_outcomes\")]\n",
    "    medium_files = [f for f in files if f.startswith(\"medium_outcomes\")]\n",
    "\n",
    "    # === Step 2: Define helper to load and combine CSVs ===\n",
    "    def load_and_combine(file_list, label):\n",
    "        dfs = []\n",
    "        for run, file in enumerate(file_list):\n",
    "            df = pd.read_csv(os.path.join(folder, file))\n",
    "            df['Total Investment Costs'] = (\n",
    "                df['Dike Investment Costs'] +\n",
    "                df['RfR Investment Costs']\n",
    "            )\n",
    "            df['Expected Annual Costs'] = (\n",
    "                df['Evacuation Costs'] +\n",
    "                df['Expected Annual Damage']\n",
    "            )\n",
    "            df['Scenario'] = f\"{label}_{run}\"\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "    # === Step 3: Load and combine each group ===\n",
    "    favourable_df = load_and_combine(favourable_files, 'Favourable')\n",
    "    unfavourable_df = load_and_combine(unfavourable_files, 'Unfavourable')\n",
    "    medium_df = load_and_combine(medium_files, 'Medium')\n",
    "\n",
    "    return favourable_df, unfavourable_df, medium_df\n",
    "\n",
    "folder_path = \"optimization_150000_seed20_results\"\n",
    "favourable_df_20, unfavourable_df_20, medium_df_20 = process_scenario_folder(folder_path)\n",
    "\n",
    "folder_path = \"optimization_150000_seed21_results\"\n",
    "favourable_df_21, unfavourable_df_21, medium_df_21 = process_scenario_folder(folder_path)\n"
   ],
   "id": "36c20240539d53cc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The policies are first selected by defining threshodls, as the pareto front minimalizes on all aspects, and some aspects we see as more important than others.\n",
    "\n",
    "Afer filtering on the thresholds, a small selection of policies is left. Due to compuational contstraints, we decided to filter even further, by picking the top 3 policies for each category when sorting and minimizing on the SORT_COLUMNS"
   ],
   "id": "de3f6539af1be049"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:06:30.095815Z",
     "start_time": "2025-06-19T23:06:30.003951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants for sort priority\n",
    "SORT_COLUMNS = [\n",
    "    'Expected Number of Deaths',\n",
    "    'Expected Annual Damage',\n",
    "    'Evacuation Costs',\n",
    "    'Total Investment Costs'\n",
    "]\n",
    "\n",
    "# Threshold quantile defaults\n",
    "DEFAULT_THRESHOLDS = {\n",
    "    'q_investment_costs': 0.75,\n",
    "    'q_dike': 0.75,\n",
    "    'q_evac': 0.50,\n",
    "    'q_damage': 0.25,\n",
    "    'death_cap': 0.02\n",
    "}\n",
    "\n",
    "def load_thresholds(df, thresholds=DEFAULT_THRESHOLDS):\n",
    "    df = df.copy()\n",
    "    df['Total Investment Costs'] = df['Dike Investment Costs'] + df['RfR Investment Costs']\n",
    "    df['Expected Annual Costs'] = df['Evacuation Costs'] + df['Expected Annual Damage']\n",
    "\n",
    "    threshold_values = {\n",
    "        'Total Investment Costs': df['Total Investment Costs'].quantile(thresholds['q_investment_costs']),\n",
    "        'Dike Investment Costs': df['Dike Investment Costs'].quantile(thresholds['q_dike']),\n",
    "        'Evacuation Costs': df['Evacuation Costs'].quantile(thresholds['q_evac']),\n",
    "        'Expected Annual Damage': df['Expected Annual Damage'].quantile(thresholds['q_damage']),\n",
    "        'Expected Number of Deaths': thresholds['death_cap']\n",
    "    }\n",
    "\n",
    "    return df, threshold_values\n",
    "\n",
    "def filter_df(df, threshold_values):\n",
    "    return df[\n",
    "        (df['Total Investment Costs'] <= threshold_values['Total Investment Costs']) &\n",
    "        (df['Dike Investment Costs'] <= threshold_values['Dike Investment Costs']) &\n",
    "        (df['Evacuation Costs'] <= threshold_values['Evacuation Costs']) &\n",
    "        (df['Expected Annual Damage'] <= threshold_values['Expected Annual Damage']) &\n",
    "        (df['Expected Number of Deaths'] <= threshold_values['Expected Number of Deaths']) &\n",
    "        (df['RfR Investment Costs'] > 0)\n",
    "    ]\n",
    "\n",
    "def select_top_policies(filtered_df, top_n=3):\n",
    "    return filtered_df.sort_values(by=SORT_COLUMNS).head(top_n)\n",
    "\n",
    "def save_policy_csv(results_df, prefix, folder_name, save=True):\n",
    "    if save:\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        filename = os.path.join(folder_name, f\"{prefix}policy.csv\")\n",
    "        results_df.to_csv(filename, index=False)\n",
    "        print(f\"Saved: {filename}\")\n",
    "\n",
    "def process_policy_sets(fav_df, med_df, unfav_df, seed):\n",
    "    fav_loaded, fav_thresholds = load_thresholds(fav_df)\n",
    "    med_loaded, med_thresholds = load_thresholds(med_df)\n",
    "    unfav_loaded, unfav_thresholds = load_thresholds(unfav_df)\n",
    "\n",
    "    fav_selected = filter_df(fav_loaded, fav_thresholds)\n",
    "    med_selected = filter_df(med_loaded, med_thresholds)\n",
    "    unfav_selected = filter_df(unfav_loaded, unfav_thresholds)\n",
    "\n",
    "    # Save filtered dataframes\n",
    "    save_policy_csv(fav_selected, f\"favourable_{seed}_\", folder_name=f\"policies_seed_{seed}\")\n",
    "    save_policy_csv(med_selected, f\"medium_{seed}_\", folder_name=f\"policies_seed_{seed}\")\n",
    "    save_policy_csv(unfav_selected, f\"unfavourable_{seed}_\", folder_name=f\"policies_seed_{seed}\")\n",
    "\n",
    "    # Top 3 selection from each category\n",
    "    top3_combined = pd.concat([\n",
    "        select_top_policies(fav_selected),\n",
    "        select_top_policies(med_selected),\n",
    "        select_top_policies(unfav_selected)\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    # Save combined top policies\n",
    "    save_policy_csv(top3_combined, f\"top3_combined_{seed}_\", folder_name=f\"policies_seed_{seed}\")\n",
    "\n",
    "    return top3_combined\n",
    "\n",
    "# Call the function for both seeds/years\n",
    "combined_top_policies_20 = process_policy_sets(\n",
    "    favourable_df_20, medium_df_20, unfavourable_df_20, seed=\"20\"\n",
    ")\n",
    "\n",
    "combined_top_policies_21 = process_policy_sets(\n",
    "    favourable_df_21, medium_df_21, unfavourable_df_21, seed=\"21\"\n",
    ")\n"
   ],
   "id": "9551d64eaf431e63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: policies_seed_20\\favourable_20_policy.csv\n",
      "Saved: policies_seed_20\\medium_20_policy.csv\n",
      "Saved: policies_seed_20\\unfavourable_20_policy.csv\n",
      "Saved: policies_seed_20\\top3_combined_20_policy.csv\n",
      "Saved: policies_seed_21\\favourable_21_policy.csv\n",
      "Saved: policies_seed_21\\medium_21_policy.csv\n",
      "Saved: policies_seed_21\\unfavourable_21_policy.csv\n",
      "Saved: policies_seed_21\\top3_combined_21_policy.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## First robustness run with 10 scenarios\n",
    "from the previous code, 9 scenarios are obtained and these 9 scenarios are run against the original 10 policies"
   ],
   "id": "d478046b4679ba27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:08:01.468264Z",
     "start_time": "2025-06-19T23:07:47.098600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the dike model and planning steps with formulation version 2\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "# Load the filtered scenario space CSV file containing scenario parameters\n",
    "scenario_collection_df = pd.read_csv(\"scenarios/filtered_scenario_space_df.csv\")\n",
    "\n",
    "# Ignore the last 9 columns which may be metrics or results, keeping only policy parameters\n",
    "\n",
    "combined_top_policies_df_20 = combined_top_policies_20.iloc[:, :-8]\n",
    "combined_top_policies_df_21 = combined_top_policies_21.iloc[:, :-8]\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "def run_policies_in_scenarios(dike_model, policy_df, scenario_df, seed):\n",
    "    # Create a timestamped output folder to store results\n",
    "    output_folder = f\"policy_scenario_results_{seed}\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Loop over each policy in the DataFrame\n",
    "    for i, (idx, policy_row) in enumerate(policy_df.iterrows()):\n",
    "        print(f\"Running policy {i}...\")\n",
    "\n",
    "        # Create an EMA Workbench Policy object from the current policy row\n",
    "        policy = Policy(f\"policy_{i}\", **policy_row.to_dict())\n",
    "\n",
    "        # Create Scenario objects for all scenarios in scenario_df\n",
    "        scenarios = []\n",
    "        for j, scenario_row in scenario_df.iterrows():\n",
    "            scenario = Scenario(f\"scenario_{j}\", **scenario_row.to_dict())\n",
    "            scenarios.append(scenario)\n",
    "\n",
    "        # Use a multiprocessing evaluator to run experiments for the given policy across all scenarios\n",
    "        with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "            experiments, outcomes = evaluator.perform_experiments(\n",
    "                scenarios=scenarios,\n",
    "                policies=[policy]\n",
    "            )\n",
    "\n",
    "        # Convert experiments (input params) to a DataFrame\n",
    "        results_df = pd.DataFrame(experiments)\n",
    "\n",
    "        # Add each outcome as a new column in the results DataFrame\n",
    "        for outcome_name, outcome_values in outcomes.items():\n",
    "            results_df[outcome_name] = outcome_values\n",
    "\n",
    "        # Save results to a CSV file inside the output folder\n",
    "        filename = os.path.join(output_folder, f\"policy_{i}_results.csv\")\n",
    "        results_df.to_csv(filename, index=False)\n",
    "        print(f\"Saved results for policy {i} to {filename}\")\n",
    "\n",
    "# Initialize model and planning steps with formulation version 2\n",
    "model, steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "# Run the policies on scenarios\n",
    "run_policies_in_scenarios(model, combined_top_policies_df_20, scenario_collection_df, 20)\n",
    "run_policies_in_scenarios(model, combined_top_policies_df_21, scenario_collection_df, 21)\n",
    "\n"
   ],
   "id": "2790ec8e9b0e50e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running policy 0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 53\u001B[39m\n\u001B[32m     50\u001B[39m model, steps = get_model_for_problem_formulation(\u001B[32m2\u001B[39m)\n\u001B[32m     52\u001B[39m \u001B[38;5;66;03m# Run the policies on scenarios\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m \u001B[43mrun_policies_in_scenarios\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcombined_top_policies_df_20\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscenario_collection_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     54\u001B[39m run_policies_in_scenarios(model, combined_top_policies_df_21, scenario_collection_df, \u001B[32m21\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mrun_policies_in_scenarios\u001B[39m\u001B[34m(dike_model, policy_df, scenario_df, seed)\u001B[39m\n\u001B[32m     28\u001B[39m     scenarios.append(scenario)\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# Use a multiprocessing evaluator to run experiments for the given policy across all scenarios\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mMultiprocessingEvaluator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdike_model\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevaluator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexperiments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutcomes\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mperform_experiments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscenarios\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscenarios\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpolicies\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[38;5;66;03m# Convert experiments (input params) to a DataFrame\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\EPA-Master\\EPA141A - Model-based Decision Making\\project\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:105\u001B[39m, in \u001B[36mBaseEvaluator.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    104\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m105\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minitialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    106\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\EPA-Master\\EPA141A - Model-based Decision Making\\project\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\futures_multiprocessing.py:288\u001B[39m, in \u001B[36mMultiprocessingEvaluator.initialize\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    285\u001B[39m \u001B[38;5;66;03m# check if we need a working directory\u001B[39;00m\n\u001B[32m    286\u001B[39m \u001B[38;5;28mself\u001B[39m.root_dir = determine_rootdir(\u001B[38;5;28mself\u001B[39m._msis)\n\u001B[32m--> \u001B[39m\u001B[32m288\u001B[39m \u001B[38;5;28mself\u001B[39m._pool = \u001B[43mmultiprocessing\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    289\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_processes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    290\u001B[39m \u001B[43m    \u001B[49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_msis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloglevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mroot_dir\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmaxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    293\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[38;5;28mself\u001B[39m.n_processes = \u001B[38;5;28mself\u001B[39m._pool._processes\n\u001B[32m    295\u001B[39m _logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mpool started with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.n_processes\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m workers\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:119\u001B[39m, in \u001B[36mBaseContext.Pool\u001B[39m\u001B[34m(self, processes, initializer, initargs, maxtasksperchild)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m'''Returns a process pool object'''\u001B[39;00m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpool\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Pool\n\u001B[32m--> \u001B[39m\u001B[32m119\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocesses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    120\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:215\u001B[39m, in \u001B[36mPool.__init__\u001B[39m\u001B[34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001B[39m\n\u001B[32m    213\u001B[39m \u001B[38;5;28mself\u001B[39m._processes = processes\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m215\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_repopulate_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    217\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pool:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:306\u001B[39m, in \u001B[36mPool._repopulate_pool\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    305\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_repopulate_pool\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_repopulate_pool_static\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mProcess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_processes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inqueue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_outqueue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_initargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_maxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_wrap_exception\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:329\u001B[39m, in \u001B[36mPool._repopulate_pool_static\u001B[39m\u001B[34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001B[39m\n\u001B[32m    327\u001B[39m w.name = w.name.replace(\u001B[33m'\u001B[39m\u001B[33mProcess\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mPoolWorker\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    328\u001B[39m w.daemon = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m329\u001B[39m \u001B[43mw\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    330\u001B[39m pool.append(w)\n\u001B[32m    331\u001B[39m util.debug(\u001B[33m'\u001B[39m\u001B[33madded worker\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001B[39m, in \u001B[36mBaseProcess.start\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process._config.get(\u001B[33m'\u001B[39m\u001B[33mdaemon\u001B[39m\u001B[33m'\u001B[39m), \\\n\u001B[32m    119\u001B[39m        \u001B[33m'\u001B[39m\u001B[33mdaemonic processes are not allowed to have children\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    120\u001B[39m _cleanup()\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m \u001B[38;5;28mself\u001B[39m._popen = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[38;5;28mself\u001B[39m._sentinel = \u001B[38;5;28mself\u001B[39m._popen.sentinel\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001B[39m, in \u001B[36mSpawnProcess._Popen\u001B[39m\u001B[34m(process_obj)\u001B[39m\n\u001B[32m    333\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    334\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_Popen\u001B[39m(process_obj):\n\u001B[32m    335\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpopen_spawn_win32\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001B[39m, in \u001B[36mPopen.__init__\u001B[39m\u001B[34m(self, process_obj)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     94\u001B[39m     reduction.dump(prep_data, to_child)\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m     \u001B[43mreduction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     97\u001B[39m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001B[39m, in \u001B[36mdump\u001B[39m\u001B[34m(obj, file, protocol)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdump\u001B[39m(obj, file, protocol=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     59\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that these policies each have data for 10 scenarios, different robustness metrics are caluclated, such as mean, std, mean regret and max regret for the different outcomes. This is done for both seeds, and for each seed the top 2 best performing are chosen (so highest robustness, lowest weighted score). The matrix used for the weighted score displays the importance of each robustness metric for each outcome.",
   "id": "96aa29fd140eb550"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:35:22.010766Z",
     "start_time": "2025-06-19T23:35:21.876425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_robustness_with_regret(df, policy_id_col, scenario_id_col, performance_cols, weights):\n",
    "    # Copy dataframe to avoid modifying original\n",
    "    regret_df = df.copy()\n",
    "\n",
    "    # Calculate regret per scenario and performance metric:\n",
    "    # Regret = (value for policy) - (best value among all policies in that scenario)\n",
    "    # This tells how much worse a policy performs compared to the best policy in each scenario\n",
    "    for col in performance_cols:\n",
    "        regret_df[f'{col} Regret'] = regret_df.groupby(scenario_id_col)[col].transform(lambda x: x - x.min())\n",
    "\n",
    "    # Group data by policy to compute summary statistics per policy\n",
    "    grouped = regret_df.groupby(policy_id_col)\n",
    "    results = []\n",
    "\n",
    "    for policy, group in grouped:\n",
    "        metrics = {'Policy': policy}\n",
    "\n",
    "        # For each performance metric, calculate raw statistics:\n",
    "        # Mean: average performance over all scenarios\n",
    "        # Std: variability in performance\n",
    "        # Max Regret: worst-case regret (how badly it can perform compared to best scenario)\n",
    "        # Mean Regret: average regret over all scenarios (typical performance gap)\n",
    "        for col in performance_cols:\n",
    "            values = group[col]\n",
    "            regrets = group[f'{col} Regret']\n",
    "\n",
    "            metrics[f'{col} Mean'] = values.mean()\n",
    "            metrics[f'{col} Std'] = values.std()\n",
    "            metrics[f'{col} Max Regret'] = regrets.max()\n",
    "            metrics[f'{col} Mean Regret'] = regrets.mean()\n",
    "\n",
    "        results.append(metrics)\n",
    "\n",
    "    robustness_df = pd.DataFrame(results)\n",
    "\n",
    "    # --- Normalization Section ---\n",
    "    # We want to combine metrics that have different scales into a single score.\n",
    "    # Normalization rescales each metric to a [0,1] range where 0 = best (lowest value),\n",
    "    # 1 = worst (highest value), so metrics are comparable.\n",
    "    for col in performance_cols:\n",
    "        for stat in ['Mean', 'Std', 'Max Regret', 'Mean Regret']:\n",
    "            metric_col = f'{col} {stat}'\n",
    "\n",
    "            # Find min and max values of this metric across all policies\n",
    "            min_val = robustness_df[metric_col].min()\n",
    "            max_val = robustness_df[metric_col].max()\n",
    "\n",
    "            # Denominator avoids division by zero if min == max (all values equal)\n",
    "            denom = max_val - min_val if max_val > min_val else 1e-9\n",
    "\n",
    "            # Normalize: subtract min then divide by range => scales to 0-1\n",
    "            robustness_df[f'{metric_col} (Norm)'] = (robustness_df[metric_col] - min_val) / denom\n",
    "\n",
    "    # --- Weighted Scoring Section ---\n",
    "    # Apply user-defined weights to normalized metrics reflecting their importance.\n",
    "    # Weights correspond to your criteria priority for mean, std, max regret, mean regret.\n",
    "    # Weighted sum gives a single score to rank policies.\n",
    "    score_cols = []\n",
    "    for col in performance_cols:\n",
    "        for stat, weight in zip(['Mean', 'Std', 'Max Regret', 'Mean Regret'], weights[col]):\n",
    "            norm_col = f'{col} {stat} (Norm)'\n",
    "            weighted_col = f'{col} {stat} Weighted'\n",
    "            robustness_df[weighted_col] = robustness_df[norm_col] * weight\n",
    "            score_cols.append(weighted_col)\n",
    "\n",
    "    # Sum all weighted metrics to get a final composite score\n",
    "    # Lower score indicates better overall performance based on priorities\n",
    "    robustness_df['Total Score'] = robustness_df[score_cols].sum(axis=1)\n",
    "\n",
    "    return robustness_df\n",
    "\n",
    "def find_best_policies(folder_path):\n",
    "    all_dfs = []\n",
    "\n",
    "    # Load all policy result CSV files from the folder\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\"_results.csv\"):\n",
    "            policy_id = file.replace(\"_results.csv\", \"\")\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            df['policy'] = policy_id\n",
    "            df['scenario'] = df.index\n",
    "\n",
    "            # Combine investment costs from different sources\n",
    "            df['Total Investment Costs'] = df['Dike Investment Costs'] + df['RfR Investment Costs']\n",
    "            df['Expected Annual Costs'] = df['Evacuation Costs'] + df['Expected Annual Damage']\n",
    "\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    if not all_dfs:\n",
    "        raise ValueError(\"No result CSV files found.\")\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    performance_columns = [\n",
    "        'Expected Number of Deaths',\n",
    "        'Expected Annual Damage',\n",
    "        'Evacuation Costs',\n",
    "        'Total Investment Costs'\n",
    "    ]\n",
    "\n",
    "    # Weights according to your priority criteria:\n",
    "    # - Mean: importance decreases from deaths to investment costs\n",
    "    # - Std: used for damage, evacuation, investment\n",
    "    # - Max Regret: only for deaths\n",
    "    # - Mean Regret: damage, evacuation, investment in descending importance\n",
    "    weights = {\n",
    "        'Expected Number of Deaths': [1.0, 1.0, 1.0, 0.01],   # Mean, Std, Max Regret, Mean Regret\n",
    "        'Expected Annual Damage':   [0.75, 0.75, 0.01, 0.5],\n",
    "        'Evacuation Costs':         [0.5, 0.5, 0.01, 0.25],\n",
    "        'Total Investment Costs':   [0.25, 0.25, 0.01, 0.01],\n",
    "    }\n",
    "\n",
    "    robustness_df = evaluate_robustness_with_regret(\n",
    "        combined_df,\n",
    "        policy_id_col='policy',\n",
    "        scenario_id_col='scenario',\n",
    "        performance_cols=performance_columns,\n",
    "        weights=weights\n",
    "    )\n",
    "\n",
    "    # Sort policies by total score ascending (lower is better)\n",
    "    sorted_df = robustness_df.sort_values('Total Score').reset_index(drop=True)\n",
    "\n",
    "    # Select top 2 policies based on the weighted score\n",
    "    best_two = sorted_df.head(2)\n",
    "\n",
    "    # Print raw performance metrics for the top 2 policies\n",
    "        # Print raw performance metrics for the top 2 policies\n",
    "    # Print raw performance metrics for the top 2 policies in a compact tabular format\n",
    "    for i, row in best_two.iterrows():\n",
    "        print(f\"\\nRank {i+1} Policy: {row['Policy']}\")\n",
    "        print(f\"{'Metric':30} {'Mean':>15} {'Std':>15} {'Max Regret':>15} {'Mean Regret':>15}\")\n",
    "        print(\"-\" * 90)\n",
    "        for col in performance_columns:\n",
    "            print(f\"{col:30} \"\n",
    "                  f\"{row[f'{col} Mean']:15.6g} \"\n",
    "                  f\"{row[f'{col} Std']:15.6g} \"\n",
    "                  f\"{row[f'{col} Max Regret']:15.6g} \"\n",
    "                  f\"{row[f'{col} Mean Regret']:15.6g}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Return the IDs and full dataframes of the two best policies for further analysis\n",
    "    best_policy_ids = best_two['Policy'].tolist()\n",
    "    dfs = [combined_df[combined_df['policy'] == pid] for pid in best_policy_ids]\n",
    "\n",
    "    return best_policy_ids, dfs\n",
    "\n",
    "\n",
    "output_folder = \"policy_scenario_results_20\"\n",
    "best_policy_ids_20, best_policy_dfs_20 = find_best_policies(output_folder)\n",
    "\n",
    "output_folder = \"policy_scenario_results_21\"\n",
    "best_policy_ids_21, best_policy_dfs_21 = find_best_policies(output_folder)\n"
   ],
   "id": "295963d01393a0d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank 1 Policy: policy_8\n",
      "Metric                                    Mean             Std      Max Regret     Mean Regret\n",
      "------------------------------------------------------------------------------------------\n",
      "Expected Number of Deaths             0.246491        0.506853         1.46415        0.185377\n",
      "Expected Annual Damage              3.8326e+08     8.12109e+08     2.64861e+08     4.95513e+07\n",
      "Evacuation Costs                             0               0               0               0\n",
      "Total Investment Costs             4.82519e+08               0     3.31315e+08     3.31315e+08\n",
      "\n",
      "Rank 2 Policy: policy_6\n",
      "Metric                                    Mean             Std      Max Regret     Mean Regret\n",
      "------------------------------------------------------------------------------------------\n",
      "Expected Number of Deaths             0.246533        0.507511         1.46415        0.185418\n",
      "Expected Annual Damage             3.82022e+08     8.12569e+08     2.64861e+08     4.83137e+07\n",
      "Evacuation Costs                             0               0               0               0\n",
      "Total Investment Costs              4.6206e+08     6.28288e-08     3.10856e+08     3.10856e+08\n",
      "\n",
      "Rank 1 Policy: policy_8\n",
      "Metric                                    Mean             Std      Max Regret     Mean Regret\n",
      "------------------------------------------------------------------------------------------\n",
      "Expected Number of Deaths             0.171675        0.151331        0.514364        0.154377\n",
      "Expected Annual Damage             2.05007e+08     1.88069e+08     3.71833e+08     1.28616e+08\n",
      "Evacuation Costs                             0               0               0               0\n",
      "Total Investment Costs             4.79195e+08               0     1.69667e+08     1.69667e+08\n",
      "\n",
      "Rank 2 Policy: policy_7\n",
      "Metric                                    Mean             Std      Max Regret     Mean Regret\n",
      "------------------------------------------------------------------------------------------\n",
      "Expected Number of Deaths              0.18842        0.153548        0.530182        0.171121\n",
      "Expected Annual Damage             2.41719e+08      2.0651e+08     3.98474e+08     1.65329e+08\n",
      "Evacuation Costs                             0               0               0               0\n",
      "Total Investment Costs              4.2729e+08     6.28288e-08     1.17762e+08     1.17762e+08\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These final four policies are now saved to be further tested for robustness",
   "id": "a07ffd7d6318e124"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T23:12:08.825508Z",
     "start_time": "2025-06-19T23:12:08.801196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_folder = 'selected_4_policies'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save policy_8 s20\n",
    "df_policy_8 = pd.DataFrame(best_policy_dfs_20[0])\n",
    "file_name_8 = f'policy_8_overview_20.csv'\n",
    "df_policy_8.to_csv(os.path.join(output_folder, file_name_8), index=False)\n",
    "\n",
    "# Save policy_6 s20\n",
    "df_policy_6 = pd.DataFrame(best_policy_dfs_20[1])\n",
    "file_name_6 = f'policy_6_overview_20.csv'\n",
    "df_policy_6.to_csv(os.path.join(output_folder, file_name_6), index=False)\n",
    "\n",
    "# Save policy_8 s21\n",
    "df_policy_8 = pd.DataFrame(best_policy_dfs_21[0])\n",
    "file_name_8 = f'policy_8_overview_21.csv'\n",
    "df_policy_8.to_csv(os.path.join(output_folder, file_name_8), index=False)\n",
    "\n",
    "# Save policy_7 s21\n",
    "df_policy_7 = pd.DataFrame(best_policy_dfs_21[1])\n",
    "file_name_7 = f'policy_7_overview_21.csv'\n",
    "df_policy_7.to_csv(os.path.join(output_folder, file_name_7), index=False)"
   ],
   "id": "ed0a05223daa4b86",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## After selecting the policies, run robustness on 100.000 new scenarios\n",
    "The code to load the data"
   ],
   "id": "4694bc7fe66ef8ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T22:25:04.741536Z",
     "start_time": "2025-06-19T22:25:04.708223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the folder path and get list of files\n",
    "folder_name = \"selected_4_policies\"\n",
    "file_list = os.listdir(folder_name)\n",
    "\n",
    "# Initialize empty lists to hold dataframes for policies_20 and policies_21\n",
    "policies_20_dfs = []\n",
    "policies_21_dfs = []\n",
    "\n",
    "for file in file_list:\n",
    "    if file.endswith('.csv'):\n",
    "        # Read the CSV\n",
    "        df = pd.read_csv(os.path.join(folder_name, file), nrows=1)\n",
    "\n",
    "        # Check if file name contains \"_20_\" or \"_21_\" and add sliced df accordingly\n",
    "        if '_20_' in file:\n",
    "            # Take rows 20 to 50 by index (i.e. iloc[19:50])\n",
    "            policies_20_dfs.append(df)\n",
    "        elif '_21_' in file:\n",
    "            policies_21_dfs.append(df)\n",
    "\n",
    "\n",
    "policies_20_df = pd.concat(policies_20_dfs, ignore_index=True).iloc[:, 19:50]\n",
    "policies_21_df = pd.concat(policies_21_dfs, ignore_index=True).iloc[:, 19:50]\n",
    "\n",
    "policies_20 = []\n",
    "\n",
    "for idx, row in policies_20_df.iterrows():\n",
    "    # Convert the row (pandas Series) to a dictionary: lever_name -> lever_value\n",
    "    lever_values = row.to_dict()\n",
    "\n",
    "    # Create a unique policy name, e.g. \"policy_20_row_0\"\n",
    "    policy_name = f\"policy_20_row_{idx}\"\n",
    "\n",
    "    # Create the Policy object\n",
    "    policy = Policy(policy_name, **lever_values)\n",
    "\n",
    "    # Append to the list\n",
    "    policies_20.append(policy)\n",
    "\n",
    "policies_21 = []\n",
    "\n",
    "for idx, row in policies_21_df.iterrows():\n",
    "    # Convert the row (pandas Series) to a dictionary: lever_name -> lever_value\n",
    "    lever_values = row.to_dict()\n",
    "\n",
    "    # Create a unique policy name, e.g. \"policy_20_row_0\"\n",
    "    policy_name = f\"policy_21_row_{idx}\"\n",
    "\n",
    "    # Create the Policy object\n",
    "    policy = Policy(policy_name, **lever_values)\n",
    "\n",
    "    # Append to the list\n",
    "    policies_21.append(policy)\n",
    "\n",
    "def save_experiments_and_outcomes(name, experiments, outcomes, folder_name=\"robustness_results\"):\n",
    "    \"\"\"\n",
    "    Saves the experiments and outcomes to CSV files in the specified folder,\n",
    "    with filenames that include a custom name and timestamp.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): Custom label for the output files (e.g., 'policy6_seed20').\n",
    "    - experiments (pd.DataFrame): The experiments DataFrame.\n",
    "    - outcomes (dict): The outcomes dictionary from the EMA Workbench.\n",
    "    - folder_name (str): The name of the folder where files will be saved. Default is \"results\".\n",
    "    \"\"\"\n",
    "    # Get timestamp\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Ensure folder exists\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # Define file paths\n",
    "    exp_path = os.path.join(folder_name, f'{name}_robustness_100000_experiments_{current_date}.csv')\n",
    "    out_path = os.path.join(folder_name, f'{name}_robustness_100000_outcomes_{current_date}.csv')\n",
    "\n",
    "    # Save experiments\n",
    "    experiments.to_csv(exp_path, index=False)\n",
    "\n",
    "    # Flatten outcomes and save\n",
    "    flattened_data = {key: value.flatten() for key, value in outcomes.items()}\n",
    "    df_outcomes = pd.DataFrame(flattened_data)\n",
    "    df_outcomes.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"Saved experiments and outcomes as '{name}' in '{folder_name}' (timestamp: {current_date})\")"
   ],
   "id": "2098006273ac3d6c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Each policy is now run again against 100.000 scenarios (others than the first 100.000, as the seed is now 21)",
   "id": "7efeab2cd81502f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T22:26:04.921364300Z",
     "start_time": "2025-06-19T22:25:10.023683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_scenarios = 100000\n",
    "np.random.seed(21)\n",
    "\n",
    "def run_policy(name, policy, n_scenarios):\n",
    "    # Load your model and define parameters\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "    with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results = evaluator.perform_experiments(\n",
    "            scenarios=n_scenarios,\n",
    "            policies=policy,\n",
    "            uncertainty_sampling=Samplers.LHS\n",
    "        )\n",
    "    experiments, outcomes = results\n",
    "    save_experiments_and_outcomes(name, experiments, outcomes)\n",
    "\n",
    "run_policy('policy_6_s20', policies_20[0], n_scenarios)\n",
    "run_policy('policy_8_s20', policies_20[1], n_scenarios)\n",
    "run_policy('policy_7_s21', policies_21[0], n_scenarios)\n",
    "run_policy('policy_8_s21', policies_21[1], n_scenarios)\n",
    "\n",
    "\n"
   ],
   "id": "5da6a30962b59d66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 72/100000 [00:11<2:05:35, 13.26it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Finally, the generation of the outcomes on a different aggregation\n",
    "\n",
    "Because of the political space, the policies are run for a different aggregation, but due to time constraints, this is only done for 50.000 scenarios."
   ],
   "id": "bae1709655197acc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "731b566eb3f5d74f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_scenarios = 50000\n",
    "np.random.seed(21)\n",
    "\n",
    "def run_policy(name, policy, n_scenarios):\n",
    "    # Load your model and define parameters\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "    with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results = evaluator.perform_experiments(\n",
    "            scenarios=n_scenarios,\n",
    "            policies=policy,\n",
    "            uncertainty_sampling=Samplers.LHS\n",
    "        )\n",
    "    experiments, outcomes = results\n",
    "    save_experiments_and_outcomes(name, experiments, outcomes)\n",
    "\n",
    "run_policy('policy_6_s20', policies_20[0], n_scenarios)\n",
    "run_policy('policy_8_s20', policies_20[1], n_scenarios)\n",
    "run_policy('policy_7_s21', policies_21[0], n_scenarios)\n",
    "run_policy('policy_8_s21', policies_21[1], n_scenarios)\n",
    "\n",
    "\n"
   ],
   "id": "51e60f4717d5383d"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
